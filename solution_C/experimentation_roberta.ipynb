{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6Z_nt6CDPmFL","5iRsx3jRavN_","Ar8n9iYLRqJ-","7PIjaoLxQETl","tmplgEhQQGa9","47YHR_RvQKOH","mqj3-EkCamIR","LdCYjvR8h4z0","IJOW-8bZYZ8w","LjMx8_hlTBFM"],"gpuType":"V100","authorship_tag":"ABX9TyMjRKWDitReM9VgqA5372Nf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\" #For running in Jack's Google Drive"],"metadata":{"id":"fGpyNWw7ZlX2","executionInfo":{"status":"ok","timestamp":1712737354295,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1712737356304,"user_tz":-60,"elapsed":2023,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"7dd5d7ad-f575-4803-cfa2-f639a94d26b8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["sys.path.append(cwk_dir)\n","from classes.evaluation import evaluate\n","from classes.preprocessing import load_data"],"metadata":{"id":"b7x9JKYX2ehs","executionInfo":{"status":"ok","timestamp":1712737357432,"user_tz":-60,"elapsed":1132,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, BertModel, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss, Dropout, Tanh\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1712737363281,"user_tz":-60,"elapsed":5852,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","from nltk.corpus import stopwords\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1712737364187,"user_tz":-60,"elapsed":924,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models/roberta\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1712740526085,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 4\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","# BERT_ID: str = 'bert-base-uncased'\n","BERT_ID: str = 'roberta-base'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1712737364188,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1712737364188,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1712737364188,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def tokenize_data(tokenizer: RobertaTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1712737364189,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"7SnGYqV91Zct","executionInfo":{"status":"ok","timestamp":1712737364189,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["(train_premises, train_hypotheses, train_labels), (dev_premises, dev_hypotheses, dev_labels) = load_data(cwk_dir)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1712737364189,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor([int(x) for x in train_labels])\n","dev_labels = torch.tensor([int(x) for x in dev_labels])"],"metadata":{"id":"Zf5_YdO13-MS","executionInfo":{"status":"ok","timestamp":1712737364677,"user_tz":-60,"elapsed":495,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1712737366975,"user_tz":-60,"elapsed":2303,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"8ef1471c-3b6b-422e-a643-5941aed5c64f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1712737395117,"user_tz":-60,"elapsed":28146,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Example of a sentence:"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHvMInfZduYR","executionInfo":{"status":"ok","timestamp":1712737395118,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"166c99ae-7477-4885-c35b-154cf56f0c9f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['<s>', 'However', ',', 'ĠFort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġa', 'Ġmilitary', 'Ġand', 'Ġnaval', 'Ġgarrison', ',', 'Ġand', 'Ġit', 'Ġprotected', 'ĠJamaica', 'Ġand', 'Ġmuch', 'Ġof', 'Ġthe', 'ĠEnglish', 'ĠCaribbean', 'Ġfor', 'Ġ250', 'Ġyears', 'Ġuntil', 'Ġthe', 'Ġadvent', 'Ġof', 'Ġste', 'ams', 'hips', 'Ġand', 'Ġyet', 'Ġanother', 'Ġearthquake', 'Ġin', 'Ġ1907', 'Ġsaw', 'Ġits', 'Ġdecline', '.', '</s>', '</s>', 'Fort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġan', 'Ġamusement', 'Ġpark', 'Ġfor', 'Ġthe', 'Ġlocals', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","Tokens: tensor([[    0, 10462,     6,  ...,     1,     1,     1],\n","        [    0,   387,  4272,  ...,     1,     1,     1],\n","        [    0,  1121,   645,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 10777,     5,  ...,     1,     1,     1],\n","        [    0, 39858,    78,  ...,     1,     1,     1],\n","        [    0,  1708,    38,  ...,     1,     1,     1]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cuinRLeI-H","executionInfo":{"status":"ok","timestamp":1712737395118,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"7edd7391-06ea-4056-a02d-aeb5c1ccccb2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 50265\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1712737395118,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1712737395118,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1712737395119,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture\n","Inspiration:\n","- https://arxiv.org/pdf/2105.03791.pdf\n","- https://aclanthology.org/D15-1075.pdf"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Buwn9hLMFvJw","executionInfo":{"status":"ok","timestamp":1712737395119,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"de16bafd-88f5-49a6-eec4-51bd4dd20263"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["model = RobertaForSequenceClassification.from_pretrained(BERT_ID, num_labels=NUM_LABELS)\n","\n","model = model.to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeDsauNmP92-","executionInfo":{"status":"ok","timestamp":1712737395506,"user_tz":-60,"elapsed":392,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"85754850-cf2f-4386-c665-6f947fc97148"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["EPOCHS = 6"],"metadata":{"id":"KvYDRn3Y442e","executionInfo":{"status":"ok","timestamp":1712737395506,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)\n","# SCHEDULER = get_constant_schedule_with_warmup(OPTIM, num_warmup_steps = int((len(train_dataset)//BATCH_SIZE) * EPOCHS))\n","SCHEDULER = get_linear_schedule_with_warmup(OPTIM, num_warmup_steps = int((len(train_dataset)//BATCH_SIZE) * 2), num_training_steps = int((len(train_dataset)//BATCH_SIZE) * EPOCHS))"],"metadata":{"id":"FWZ8X9VITCdA","executionInfo":{"status":"ok","timestamp":1712737396543,"user_tz":-60,"elapsed":1040,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ","executionInfo":{"status":"ok","timestamp":1712737396543,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["patience = 2\n","min_delta = 0.05\n","best_val_loss = 1000\n","current_patience = 0\n","\n","best_model_filename: str = \"best_solution_C.pt\""],"metadata":{"id":"NpX0z8LUVfKn","executionInfo":{"status":"ok","timestamp":1712737396544,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    labels=labels)\n","\n","    loss = outputs.loss\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.logits.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","    SCHEDULER.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      labels=labels)\n","\n","    loss = outputs.loss\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(outputs.logits.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")\n","\n","  #Saving best model so far\n","  if avg_val_loss < best_val_loss:\n","    torch.save(model.state_dict(), os.path.join(models_dir, best_model_filename))\n","    print(f\"Best model recorded at epoch {epoch+1}\")\n","\n","  #Early stopping\n","  if avg_val_loss < (best_val_loss - min_delta):\n","    best_val_loss = avg_val_loss\n","    current_patience = 0\n","  else:\n","    current_patience += 1\n","    if current_patience >= patience:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"878c022c-6c28-4ce7-b856-d0e132fcc582","executionInfo":{"status":"ok","timestamp":1712739444563,"user_tz":-60,"elapsed":1976197,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.6845790059347181, Training Average Loss: 0.5401172355336942\n","Epoch 1, Validation Average Accuracy: 0.8706726013847677, Validation Average Loss: 0.31753246464078433\n","Best model recorded at epoch 1\n","Epoch 2, Train Average Accuracy: 0.8752781899109793, Training Average Loss: 0.30553031959557125\n","Epoch 2, Validation Average Accuracy: 0.880501978239367, Validation Average Loss: 0.2995949630633837\n","Epoch 3, Train Average Accuracy: 0.9244250741839762, Training Average Loss: 0.19701787733572373\n","Epoch 3, Validation Average Accuracy: 0.8864985163204748, Validation Average Loss: 0.3190696695487869\n","Early stopping at epoch 3\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1712739456953,"user_tz":-60,"elapsed":1724,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Load in the best saved model\n","# model.load_state_dict(torch.load(os.path.join(models_dir, best_model_filename)))"],"metadata":{"id":"6qfQjsE2lh2z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712741305479,"user_tz":-60,"elapsed":2293,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"4b876d65-a924-47e4-9535-e55ee572c229"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_logits = []\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    labels=labels)\n","\n","  predicted_logits.extend(outputs.logits.detach().cpu())"],"metadata":{"id":"28szS3zhaNn8","executionInfo":{"status":"ok","timestamp":1712741366369,"user_tz":-60,"elapsed":60352,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["test_metrics = evaluate(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))\n","test_metrics.to_csv(os.path.join(results_dir, \"roberta_metrics.csv\"), index=False)\n","test_metrics.head()"],"metadata":{"id":"ykToO7-7pZzj","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1712741366379,"user_tz":-60,"elapsed":146,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"054d8eae-3436-4373-d21d-b539f947786f"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Accuracy  Precision  Macro Precision  Weighted Macro Precision   Recall  \\\n","0  0.878284   0.894362         0.878277                    0.8788  0.86659   \n","\n","   Macro Recall  Weighted Macro Recall  F1-Score  Macro F1-Score  \\\n","0      0.878677               0.878284  0.880257        0.878251   \n","\n","   Weighted Macro F1-Score       MCC      Loss  \n","0                 0.878316  0.756954  1.764266  "],"text/html":["\n","  <div id=\"df-efe3fa87-0c90-4ba5-8410-305c325412ad\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Macro Precision</th>\n","      <th>Weighted Macro Precision</th>\n","      <th>Recall</th>\n","      <th>Macro Recall</th>\n","      <th>Weighted Macro Recall</th>\n","      <th>F1-Score</th>\n","      <th>Macro F1-Score</th>\n","      <th>Weighted Macro F1-Score</th>\n","      <th>MCC</th>\n","      <th>Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.878284</td>\n","      <td>0.894362</td>\n","      <td>0.878277</td>\n","      <td>0.8788</td>\n","      <td>0.86659</td>\n","      <td>0.878677</td>\n","      <td>0.878284</td>\n","      <td>0.880257</td>\n","      <td>0.878251</td>\n","      <td>0.878316</td>\n","      <td>0.756954</td>\n","      <td>1.764266</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efe3fa87-0c90-4ba5-8410-305c325412ad')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-efe3fa87-0c90-4ba5-8410-305c325412ad button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-efe3fa87-0c90-4ba5-8410-305c325412ad');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_metrics","summary":"{\n  \"name\": \"test_metrics\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8782841027163426,\n        \"max\": 0.8782841027163426,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8782841027163426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8943620178041543,\n        \"max\": 0.8943620178041543,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8943620178041543\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8782769399980082,\n        \"max\": 0.8782769399980082,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8782769399980082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8787998184364149,\n        \"max\": 0.8787998184364149,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8787998184364149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8665899942495687,\n        \"max\": 0.8665899942495687,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8665899942495687\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8786770161490249,\n        \"max\": 0.8786770161490249,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8786770161490249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8782841027163426,\n        \"max\": 0.8782841027163426,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8782841027163426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8802570093457943,\n        \"max\": 0.8802570093457943,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8802570093457943\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8782510522128912,\n        \"max\": 0.8782510522128912,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8782510522128912\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8783162599629439,\n        \"max\": 0.8783162599629439,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8783162599629439\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7569538504200358,\n        \"max\": 0.7569538504200358,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7569538504200358\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.7642656847092515,\n        \"max\": 1.7642656847092515,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.7642656847092515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":60}]}]}