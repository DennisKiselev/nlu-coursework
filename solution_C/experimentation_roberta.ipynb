{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6Z_nt6CDPmFL","5iRsx3jRavN_","Ar8n9iYLRqJ-","7PIjaoLxQETl","tmplgEhQQGa9","LdCYjvR8h4z0","T5P9yW21YYd3","IJOW-8bZYZ8w","LjMx8_hlTBFM"],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyMtQaMKlZK7avbJE0eetPfD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\" #For running in Jack's Google Drive"],"metadata":{"id":"fGpyNWw7ZlX2","executionInfo":{"status":"ok","timestamp":1713798474666,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1713798476810,"user_tz":-60,"elapsed":2153,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"e80b499f-44ac-4880-9544-f54779134217"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["sys.path.append(cwk_dir)\n","from classes.evaluation import evaluate\n","from classes.preprocessing import load_data, augment_data"],"metadata":{"id":"b7x9JKYX2ehs","executionInfo":{"status":"ok","timestamp":1713798493251,"user_tz":-60,"elapsed":5256,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4615b36-cd37-4c43-9553-d75987fc416a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaModel, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss, Dropout, Tanh\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1713798526126,"user_tz":-60,"elapsed":4609,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1713798526544,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models_C\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1713798496157,"user_tz":-60,"elapsed":329,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 6\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","# BERT_ID: str = 'bert-base-uncased'\n","BERT_ID: str = 'roberta-base'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1713798496582,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1713798496582,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1713798496583,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def tokenize_data(tokenizer: RobertaTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":321,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"7SnGYqV91Zct","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["test = [1,2,3,4,5]\n","index = 3\n","test = test[:(index - 1)] + test[(index):]\n","test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZK3lXxmnXQbw","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"42fd223d-bc6b-4764-dd6b-8400f127781d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 4, 5]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["(train_premises, train_hypotheses, train_labels), (dev_premises, dev_hypotheses, dev_labels) = load_data(cwk_dir)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1713798651130,"user_tz":-60,"elapsed":315,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor([int(x) for x in train_labels])\n","dev_labels = torch.tensor([int(x) for x in dev_labels])"],"metadata":{"id":"Zf5_YdO13-MS","executionInfo":{"status":"ok","timestamp":1713798651538,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### Data Augmentation\n","Different data augmentations are inspired by the paper found [here](https://link.springer.com/article/10.1186/s40537-021-00492-0)"],"metadata":{"id":"N5OAI9xxLGjP"}},{"cell_type":"code","source":["print(f\"{len(train_premises)} samples before augmentation\")\n","train_premises, train_hypotheses, train_labels = augment_data(train_premises, train_hypotheses, train_labels, premise_quantity = 3, hypothesis_quantity=3)\n","train_labels = torch.tensor(train_labels)\n","print(f\"{len(train_premises)} samples after augmentation\")"],"metadata":{"id":"1wiNhhX9cGbn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713798659603,"user_tz":-60,"elapsed":8067,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"842b150e-454d-4598-9928-22ffd5d892ee"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["26944 samples before augmentation\n","48579 samples after augmentation\n"]}]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1713798659603,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1713798687228,"user_tz":-60,"elapsed":27636,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["### Example"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"id":"gHvMInfZduYR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713798687229,"user_tz":-60,"elapsed":48,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"c81bf8d9-537d-4e09-ac69-bff63299c25b"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['<s>', 'However', ',', 'ĠFort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġa', 'Ġmilitary', 'Ġand', 'Ġnaval', 'Ġgarrison', ',', 'Ġand', 'Ġit', 'Ġprotected', 'ĠJamaica', 'Ġand', 'Ġmuch', 'Ġof', 'Ġthe', 'ĠEnglish', 'ĠCaribbean', 'Ġfor', 'Ġ250', 'Ġyears', 'Ġuntil', 'Ġthe', 'Ġadvent', 'Ġof', 'Ġste', 'ams', 'hips', 'Ġand', 'Ġyet', 'Ġanother', 'Ġearthquake', 'Ġin', 'Ġ1907', 'Ġsaw', 'Ġits', 'Ġdecline', '.', '</s>', '</s>', 'Fort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġan', 'Ġamusement', 'Ġpark', 'Ġfor', 'Ġthe', 'Ġlocals', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","Tokens: tensor([[    0, 10462,     6,  ...,     1,     1,     1],\n","        [    0,   387,  4272,  ...,     1,     1,     1],\n","        [    0,  1121,   645,  ...,     1,     1,     1],\n","        ...,\n","        [    0,  2137,     5,  ...,     1,     1,     1],\n","        [    0,  8155,  6294,  ...,     1,     1,     1],\n","        [    0,  4297,   939,  ...,     1,     1,     1]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"id":"02cuinRLeI-H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713798687230,"user_tz":-60,"elapsed":37,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"f778ba1c-9ba1-43aa-d93e-074f39777b33"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 50265\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1713798687230,"user_tz":-60,"elapsed":34,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1713798687230,"user_tz":-60,"elapsed":32,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1713798687231,"user_tz":-60,"elapsed":30,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture\n","Inspiration:\n","- https://arxiv.org/pdf/2105.03791.pdf\n","- https://aclanthology.org/D15-1075.pdf\n","\n","A larger network is better:\n","- https://arxiv.org/pdf/2110.01518.pdf"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Buwn9hLMFvJw","executionInfo":{"status":"ok","timestamp":1713798687231,"user_tz":-60,"elapsed":29,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"a7f0594a-93b0-48d1-a5ee-1f03506fa1a4"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["model = RobertaForSequenceClassification.from_pretrained(BERT_ID, num_labels=NUM_LABELS)\n","\n","model = model.to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeDsauNmP92-","executionInfo":{"status":"ok","timestamp":1713798687660,"user_tz":-60,"elapsed":454,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"3f747271-c400-4264-d5a4-ba80e35ddac3"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)\n","\n","num_warmup_steps = int(len(train_dataset) * 1)\n","num_training_steps = int(len(train_dataset) * EPOCHS)\n","SCHEDULER = get_linear_schedule_with_warmup(OPTIM, num_warmup_steps = num_warmup_steps, num_training_steps = num_training_steps)\n","\n","print(f\"num_warmup_steps: {num_warmup_steps}\")\n","print(f\"num_training_steps: {num_training_steps}\")"],"metadata":{"id":"FWZ8X9VITCdA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713798687660,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"d8423d16-c2bf-40c9-e53e-2eaebbffd8ae"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["num_warmup_steps: 38864\n","num_training_steps: 233184\n"]}]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ","executionInfo":{"status":"ok","timestamp":1713798687661,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["patience = 2\n","min_delta = 0.01\n","best_val_loss = 1000\n","current_patience = 0\n","\n","best_model_filename: str = \"best_solution_C.pt\""],"metadata":{"id":"NpX0z8LUVfKn","executionInfo":{"status":"ok","timestamp":1713798687662,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    labels=labels)\n","\n","    loss = outputs.loss\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.logits.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","    SCHEDULER.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      labels=labels)\n","\n","    loss = outputs.loss.detach().cpu().numpy()\n","    logits = outputs.logits.detach().cpu().numpy()\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")\n","\n","  #Early stopping\n","  if avg_val_loss < (best_val_loss - min_delta):\n","    best_val_loss = avg_val_loss\n","    current_patience = 0\n","\n","    #Save the best model so far\n","    torch.save(model.state_dict(), os.path.join(models_dir, best_model_filename))\n","    print(f\"Best model recorded at epoch {epoch+1}\")\n","  else:\n","    current_patience += 1\n","    if current_patience >= patience:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"2785857d-8d57-4ad5-c576-95c2549553f3","executionInfo":{"status":"ok","timestamp":1713805695048,"user_tz":-60,"elapsed":2919096,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.50537772745986, Training Average Loss: 0.6975276974455816\n","Epoch 1, Validation Average Accuracy: 0.642406798245614, Validation Average Loss: 0.664470794953798\n","Best model recorded at epoch 1\n","Epoch 2, Train Average Accuracy: 0.7799505969534788, Training Average Loss: 0.46029876915146756\n","Epoch 2, Validation Average Accuracy: 0.8315858004385965, Validation Average Loss: 0.38622917982406524\n","Best model recorded at epoch 2\n","Epoch 3, Train Average Accuracy: 0.8500668999588308, Training Average Loss: 0.34425945689969956\n","Epoch 3, Validation Average Accuracy: 0.8509457236842105, Validation Average Loss: 0.34885755574673805\n","Best model recorded at epoch 3\n","Epoch 4, Train Average Accuracy: 0.8843145327295183, Training Average Loss: 0.27830680645158773\n","Epoch 4, Validation Average Accuracy: 0.8667763157894737, Validation Average Loss: 0.3472947622695325\n","Epoch 5, Train Average Accuracy: 0.9128756689995883, Training Average Loss: 0.21690758174003863\n","Epoch 5, Validation Average Accuracy: 0.8695175438596491, Validation Average Loss: 0.31479889761632013\n","Best model recorded at epoch 5\n","Epoch 6, Train Average Accuracy: 0.9385549608892548, Training Average Loss: 0.15803811554037825\n","Epoch 6, Validation Average Accuracy: 0.8793174342105263, Validation Average Loss: 0.3169857790489914\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1713805700355,"user_tz":-60,"elapsed":5311,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Load in the best saved model\n","model.load_state_dict(torch.load(os.path.join(models_dir, best_model_filename))) #Disabled loading in the best model so far. Found that the later model performs better"],"metadata":{"id":"6qfQjsE2lh2z","executionInfo":{"status":"ok","timestamp":1713805701378,"user_tz":-60,"elapsed":1022,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4a539bc-e225-49e1-9d37-0bffc85b75f1"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_logits = []\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    labels=labels)\n","\n","  predicted_logits.extend(outputs.logits.detach().cpu())"],"metadata":{"id":"28szS3zhaNn8","executionInfo":{"status":"ok","timestamp":1713805760628,"user_tz":-60,"elapsed":59250,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["test_metrics = evaluate(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))\n","test_metrics.to_csv(os.path.join(results_dir, \"roberta_metrics.csv\"), index=False)\n","test_metrics.head()"],"metadata":{"id":"ykToO7-7pZzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conf_mat = draw_confusion_matrix(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))"],"metadata":{"id":"W64aU4t0QjrP","colab":{"base_uri":"https://localhost:8080/","height":276},"executionInfo":{"status":"error","timestamp":1713805761797,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"1e09ee6b-c4f7-4202-f76d-3d19e3ef41ca"},"execution_count":54,"outputs":[{"ename":"NameError","evalue":"name 'draw_confusion_matrix' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-a380cf02c918>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'draw_confusion_matrix' is not defined"]},{"output_type":"error","ename":"NameError","evalue":"name 'draw_confusion_matrix' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-a380cf02c918>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'draw_confusion_matrix' is not defined"]}]}]}