{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6Z_nt6CDPmFL","5iRsx3jRavN_","Ar8n9iYLRqJ-","7PIjaoLxQETl","LdCYjvR8h4z0"],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyMrRbTJRx85b3AdU/OaAGhb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5914f6e730b640d19989c07a7dc9d937":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09a43caf655c422ab89b3b2e9683338e","IPY_MODEL_9703de7fed504dd0ba8c5f0100fa06da","IPY_MODEL_8fb2e7460d2d44498130092903d0ab02"],"layout":"IPY_MODEL_49ffd5dcbce949978d6dedc36b99bef9"}},"09a43caf655c422ab89b3b2e9683338e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0ceed72eaa74c4a8e4270291744f6b2","placeholder":"​","style":"IPY_MODEL_eb7db677c3c04e4d82d28ad013b96dc2","value":"model.safetensors: 100%"}},"9703de7fed504dd0ba8c5f0100fa06da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7576431cf682421db6b2dccb7878e00b","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb35a8b5c63c4d31ac115276c3515373","value":498818054}},"8fb2e7460d2d44498130092903d0ab02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a7d88076c8246df864cf05f5d77ed09","placeholder":"​","style":"IPY_MODEL_1ff6265addb341a8904748fedbba93c9","value":" 499M/499M [00:01&lt;00:00, 377MB/s]"}},"49ffd5dcbce949978d6dedc36b99bef9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ceed72eaa74c4a8e4270291744f6b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb7db677c3c04e4d82d28ad013b96dc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7576431cf682421db6b2dccb7878e00b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb35a8b5c63c4d31ac115276c3515373":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a7d88076c8246df864cf05f5d77ed09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff6265addb341a8904748fedbba93c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\" #For running in Jack's Google Drive"],"metadata":{"id":"fGpyNWw7ZlX2","executionInfo":{"status":"ok","timestamp":1713260211894,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1713260213735,"user_tz":-60,"elapsed":1847,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"72aa68f9-a22c-4285-960b-c620292b1136"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["sys.path.append(cwk_dir)\n","from classes.evaluation import evaluate\n","from classes.preprocessing import load_data, augment_data"],"metadata":{"id":"b7x9JKYX2ehs","executionInfo":{"status":"ok","timestamp":1713260215369,"user_tz":-60,"elapsed":1639,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cb5761b-7ed1-4a64-81a9-be5803c52ae3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaModel, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss, Dropout, Tanh\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1713260217281,"user_tz":-60,"elapsed":1916,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1713260217616,"user_tz":-60,"elapsed":339,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models/roberta\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1713260217616,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 6\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","# BERT_ID: str = 'bert-base-uncased'\n","BERT_ID: str = 'roberta-base'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1713260217616,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1713260217617,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1713260217617,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def tokenize_data(tokenizer: RobertaTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1713260217617,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"7SnGYqV91Zct","executionInfo":{"status":"ok","timestamp":1713260217617,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test = [1,2,3,4,5]\n","index = 3\n","test = test[:(index - 1)] + test[(index):]\n","test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZK3lXxmnXQbw","executionInfo":{"status":"ok","timestamp":1713260217617,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"3317aa32-a0ac-455d-9cd3-e1d3c8aff3e5"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 4, 5]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["(train_premises, train_hypotheses, train_labels), (dev_premises, dev_hypotheses, dev_labels) = load_data(cwk_dir)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1713271870141,"user_tz":-60,"elapsed":736,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor([int(x) for x in train_labels])\n","dev_labels = torch.tensor([int(x) for x in dev_labels])"],"metadata":{"id":"Zf5_YdO13-MS","executionInfo":{"status":"ok","timestamp":1713271870780,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["### Data Augmentation\n","Different data augmentations are inspired by the paper found [here](https://link.springer.com/article/10.1186/s40537-021-00492-0)"],"metadata":{"id":"N5OAI9xxLGjP"}},{"cell_type":"code","source":["# print(f\"{len(train_premises)} samples before augmentation\")\n","# train_premises, train_hypotheses, train_labels = augment_data(train_premises, train_hypotheses, train_labels, premise_quantity = 3, hypothesis_quantity=3)\n","# train_labels = torch.tensor(train_labels)\n","# print(f\"{len(train_premises)} samples after augmentation\")"],"metadata":{"id":"1wiNhhX9cGbn","executionInfo":{"status":"ok","timestamp":1713271870780,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1713271870781,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":15555,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":["Example of a sentence:"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHvMInfZduYR","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":22,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"2374fef8-a6ea-4d50-b7bd-3a7ff083a459"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['<s>', 'However', ',', 'ĠFort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġa', 'Ġmilitary', 'Ġand', 'Ġnaval', 'Ġgarrison', ',', 'Ġand', 'Ġit', 'Ġprotected', 'ĠJamaica', 'Ġand', 'Ġmuch', 'Ġof', 'Ġthe', 'ĠEnglish', 'ĠCaribbean', 'Ġfor', 'Ġ250', 'Ġyears', 'Ġuntil', 'Ġthe', 'Ġadvent', 'Ġof', 'Ġste', 'ams', 'hips', 'Ġand', 'Ġyet', 'Ġanother', 'Ġearthquake', 'Ġin', 'Ġ1907', 'Ġsaw', 'Ġits', 'Ġdecline', '.', '</s>', '</s>', 'Fort', 'ĠCharles', 'Ġwas', 'Ġrebuilt', 'Ġas', 'Ġan', 'Ġamusement', 'Ġpark', 'Ġfor', 'Ġthe', 'Ġlocals', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n","Tokens: tensor([[    0, 10462,     6,  ...,     1,     1,     1],\n","        [    0,   387,  4272,  ...,     1,     1,     1],\n","        [    0,  1121,   645,  ...,     1,     1,     1],\n","        ...,\n","        [    0, 10777,     5,  ...,     1,     1,     1],\n","        [    0, 39858,    78,  ...,     1,     1,     1],\n","        [    0,  1708,    38,  ...,     1,     1,     1]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cuinRLeI-H","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"f33df829-7b84-4a50-988b-255845d5d624"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 50265\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1713271886334,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture\n","Inspiration:\n","- https://arxiv.org/pdf/2105.03791.pdf\n","- https://aclanthology.org/D15-1075.pdf\n","\n","A larger network is better:\n","- https://arxiv.org/pdf/2110.01518.pdf"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Buwn9hLMFvJw","executionInfo":{"status":"ok","timestamp":1713260255556,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"d8363e9d-7857-48c1-d5ef-2ed8a94effb1"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["model = RobertaForSequenceClassification.from_pretrained(BERT_ID, num_labels=NUM_LABELS)\n","\n","model = model.to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847,"referenced_widgets":["5914f6e730b640d19989c07a7dc9d937","09a43caf655c422ab89b3b2e9683338e","9703de7fed504dd0ba8c5f0100fa06da","8fb2e7460d2d44498130092903d0ab02","49ffd5dcbce949978d6dedc36b99bef9","b0ceed72eaa74c4a8e4270291744f6b2","eb7db677c3c04e4d82d28ad013b96dc2","7576431cf682421db6b2dccb7878e00b","fb35a8b5c63c4d31ac115276c3515373","0a7d88076c8246df864cf05f5d77ed09","1ff6265addb341a8904748fedbba93c9"]},"id":"XeDsauNmP92-","executionInfo":{"status":"ok","timestamp":1713260257771,"user_tz":-60,"elapsed":2223,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"8f0b291c-3c7b-42bd-a2f2-a812e6a59b00"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5914f6e730b640d19989c07a7dc9d937"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaForSequenceClassification(\n","  (roberta): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): RobertaClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)\n","SCHEDULER = get_linear_schedule_with_warmup(OPTIM, num_warmup_steps = int(len(train_dataset) * 1), num_training_steps = int(len(train_dataset) * EPOCHS))"],"metadata":{"id":"FWZ8X9VITCdA","executionInfo":{"status":"ok","timestamp":1713260258237,"user_tz":-60,"elapsed":470,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ","executionInfo":{"status":"ok","timestamp":1713260258237,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["patience = 2\n","min_delta = 0.01\n","best_val_loss = 1000\n","current_patience = 0\n","\n","best_model_filename: str = \"best_solution_C.pt\""],"metadata":{"id":"NpX0z8LUVfKn","executionInfo":{"status":"ok","timestamp":1713260258238,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    labels=labels)\n","\n","    loss = outputs.loss\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.logits.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","    SCHEDULER.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      labels=labels)\n","\n","    loss = outputs.loss.detach().cpu().numpy()\n","    logits = outputs.logits.detach().cpu().numpy()\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")\n","\n","  #Early stopping\n","  if avg_val_loss < (best_val_loss - min_delta):\n","    best_val_loss = avg_val_loss\n","    current_patience = 0\n","\n","    #Save the best model so far\n","    torch.save(model.state_dict(), os.path.join(models_dir, best_model_filename))\n","    print(f\"Best model recorded at epoch {epoch+1}\")\n","  else:\n","    current_patience += 1\n","    if current_patience >= patience:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"f514472c-b540-4efa-be0e-19f8abf2fc45","executionInfo":{"status":"ok","timestamp":1713267221456,"user_tz":-60,"elapsed":94694,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.515676738410596, Training Average Loss: 0.6933099961784107\n","Epoch 1, Validation Average Accuracy: 0.6764427625354777, Validation Average Loss: 0.6401590467091428\n","Best model recorded at epoch 1\n","Epoch 2, Train Average Accuracy: 0.7984012831125827, Training Average Loss: 0.43885600846260786\n","Epoch 2, Validation Average Accuracy: 0.8370683538315988, Validation Average Loss: 0.37089154372201455\n","Best model recorded at epoch 2\n","Epoch 3, Train Average Accuracy: 0.8518211920529801, Training Average Loss: 0.34089778601161097\n","Epoch 3, Validation Average Accuracy: 0.8559307000946075, Validation Average Loss: 0.3300631187843862\n","Best model recorded at epoch 3\n","Epoch 4, Train Average Accuracy: 0.8877793874172185, Training Average Loss: 0.2723777720878912\n","Epoch 4, Validation Average Accuracy: 0.870727885525071, Validation Average Loss: 0.30752891174129005\n","Best model recorded at epoch 4\n","Epoch 5, Train Average Accuracy: 0.9160544288079471, Training Average Loss: 0.20748002258929676\n","Epoch 5, Validation Average Accuracy: 0.8809868732261117, Validation Average Loss: 0.3057684834263232\n","Epoch 6, Train Average Accuracy: 0.9399317052980133, Training Average Loss: 0.15572767696803627\n","Epoch 6, Validation Average Accuracy: 0.8878015610217598, Validation Average Loss: 0.3197434325039461\n","Early stopping at epoch 6\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1713267228869,"user_tz":-60,"elapsed":7417,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Load in the best saved model\n","model.load_state_dict(torch.load(os.path.join(models_dir, best_model_filename))) #Disabled loading in the best model so far. Found that the later model performs better"],"metadata":{"id":"6qfQjsE2lh2z","executionInfo":{"status":"ok","timestamp":1713271903059,"user_tz":-60,"elapsed":921,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9a46e4f3-ae3f-4b8b-9b31-671b198d00a3"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_logits = []\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    labels=labels)\n","\n","  predicted_logits.extend(outputs.logits.detach().cpu())"],"metadata":{"id":"28szS3zhaNn8","executionInfo":{"status":"ok","timestamp":1713271964293,"user_tz":-60,"elapsed":59843,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["test_metrics = evaluate(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))\n","test_metrics.to_csv(os.path.join(results_dir, \"roberta_metrics.csv\"), index=False)\n","test_metrics.head()"],"metadata":{"id":"ykToO7-7pZzj","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1713271964294,"user_tz":-60,"elapsed":42,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"1ff5b95f-e639-4b59-d7cb-9fad7b7654f8"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Accuracy  Precision  Macro Precision  Weighted Macro Precision    Recall  \\\n","0  0.879917   0.879875         0.879919                  0.879917  0.888729   \n","\n","   Macro Recall  Weighted Macro Recall  F1-Score  Macro F1-Score  \\\n","0      0.879621               0.879917   0.88428        0.879746   \n","\n","   Weighted Macro F1-Score       MCC      Loss  \n","0                 0.879893  0.759539  1.751438  "],"text/html":["\n","  <div id=\"df-832185a2-284b-47ec-8fed-a7c0ded989e1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Macro Precision</th>\n","      <th>Weighted Macro Precision</th>\n","      <th>Recall</th>\n","      <th>Macro Recall</th>\n","      <th>Weighted Macro Recall</th>\n","      <th>F1-Score</th>\n","      <th>Macro F1-Score</th>\n","      <th>Weighted Macro F1-Score</th>\n","      <th>MCC</th>\n","      <th>Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.879917</td>\n","      <td>0.879875</td>\n","      <td>0.879919</td>\n","      <td>0.879917</td>\n","      <td>0.888729</td>\n","      <td>0.879621</td>\n","      <td>0.879917</td>\n","      <td>0.88428</td>\n","      <td>0.879746</td>\n","      <td>0.879893</td>\n","      <td>0.759539</td>\n","      <td>1.751438</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-832185a2-284b-47ec-8fed-a7c0ded989e1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-832185a2-284b-47ec-8fed-a7c0ded989e1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-832185a2-284b-47ec-8fed-a7c0ded989e1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_metrics","summary":"{\n  \"name\": \"test_metrics\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8799168769481965,\n        \"max\": 0.8799168769481965,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8799168769481965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8798747509251352,\n        \"max\": 0.8798747509251352,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8798747509251352\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8799187650407314,\n        \"max\": 0.8799187650407314,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8799187650407314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8799173342716479,\n        \"max\": 0.8799173342716479,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8799173342716479\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8887291546866015,\n        \"max\": 0.8887291546866015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8887291546866015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8796207909057432,\n        \"max\": 0.8796207909057432,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8796207909057432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8799168769481965,\n        \"max\": 0.8799168769481965,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8799168769481965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8842797882992418,\n        \"max\": 0.8842797882992418,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8842797882992418\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Macro F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8797459407329928,\n        \"max\": 0.8797459407329928,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8797459407329928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weighted Macro F1-Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8798933227453141,\n        \"max\": 0.8798933227453141,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8798933227453141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MCC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7595394974975184,\n        \"max\": 0.7595394974975184,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7595394974975184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 1.751437629418376,\n        \"max\": 1.751437629418376,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.751437629418376\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":47}]}]}