{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["5iRsx3jRavN_","Ar8n9iYLRqJ-","NNhHNF_7QCLR","7PIjaoLxQETl","tmplgEhQQGa9","LdCYjvR8h4z0","T5P9yW21YYd3","IJOW-8bZYZ8w","LjMx8_hlTBFM","QaqeotdSaMPX"],"gpuType":"V100","machine_shape":"hm","authorship_tag":"ABX9TyMtQaMKlZK7avbJE0eetPfD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\" #For running in Jack's Google Drive"],"metadata":{"id":"fGpyNWw7ZlX2","executionInfo":{"status":"ok","timestamp":1713798474666,"user_tz":-60,"elapsed":10,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1713798476810,"user_tz":-60,"elapsed":2153,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"e80b499f-44ac-4880-9544-f54779134217"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["sys.path.append(cwk_dir)\n","from classes.evaluation import evaluate\n","from classes.preprocessing import load_data, augment_data"],"metadata":{"id":"b7x9JKYX2ehs","executionInfo":{"status":"ok","timestamp":1713798493251,"user_tz":-60,"elapsed":5256,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4615b36-cd37-4c43-9553-d75987fc416a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaModel, get_constant_schedule_with_warmup, get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss, Dropout, Tanh\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1713798526126,"user_tz":-60,"elapsed":4609,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1713798526544,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models_C\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1713798496157,"user_tz":-60,"elapsed":329,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 6\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","# BERT_ID: str = 'bert-base-uncased'\n","BERT_ID: str = 'roberta-base'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1713798496582,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1713798496582,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1713798496583,"user_tz":-60,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def tokenize_data(tokenizer: RobertaTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":321,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"7SnGYqV91Zct","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["test = [1,2,3,4,5]\n","index = 3\n","test = test[:(index - 1)] + test[(index):]\n","test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZK3lXxmnXQbw","executionInfo":{"status":"ok","timestamp":1713798529983,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"42fd223d-bc6b-4764-dd6b-8400f127781d"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 4, 5]"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["(train_premises, train_hypotheses, train_labels), (dev_premises, dev_hypotheses, dev_labels) = load_data(cwk_dir)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1713798651130,"user_tz":-60,"elapsed":315,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor([int(x) for x in train_labels])\n","dev_labels = torch.tensor([int(x) for x in dev_labels])"],"metadata":{"id":"Zf5_YdO13-MS","executionInfo":{"status":"ok","timestamp":1713798651538,"user_tz":-60,"elapsed":2,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["### Data Augmentation\n","Different data augmentations are inspired by the paper found [here](https://link.springer.com/article/10.1186/s40537-021-00492-0)"],"metadata":{"id":"N5OAI9xxLGjP"}},{"cell_type":"code","source":["print(f\"{len(train_premises)} samples before augmentation\")\n","train_premises, train_hypotheses, train_labels = augment_data(train_premises, train_hypotheses, train_labels, premise_quantity = 3, hypothesis_quantity=3)\n","train_labels = torch.tensor(train_labels)\n","print(f\"{len(train_premises)} samples after augmentation\")"],"metadata":{"id":"1wiNhhX9cGbn","colab":{"base_uri":"https://localhost:8080/"},"outputId":"842b150e-454d-4598-9928-22ffd5d892ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["26944 samples before augmentation\n"]}]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"id":"_mHVdTUoRcY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Example"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"id":"gHvMInfZduYR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"id":"02cuinRLeI-H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture\n","Inspiration:\n","- https://arxiv.org/pdf/2105.03791.pdf\n","- https://aclanthology.org/D15-1075.pdf\n","\n","A larger network is better:\n","- https://arxiv.org/pdf/2110.01518.pdf"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"id":"Buwn9hLMFvJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = RobertaForSequenceClassification.from_pretrained(BERT_ID, num_labels=NUM_LABELS)\n","\n","model = model.to(device)\n","model"],"metadata":{"id":"XeDsauNmP92-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)\n","\n","num_warmup_steps = int(len(train_dataset) * 1)\n","num_training_steps = int(len(train_dataset) * EPOCHS)\n","SCHEDULER = get_linear_schedule_with_warmup(OPTIM, num_warmup_steps = num_warmup_steps, num_training_steps = num_training_steps)\n","\n","print(f\"num_warmup_steps: {num_warmup_steps}\")\n","print(f\"num_training_steps: {num_training_steps}\")"],"metadata":{"id":"FWZ8X9VITCdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["patience = 2\n","min_delta = 0.01\n","best_val_loss = 1000\n","current_patience = 0\n","\n","best_model_filename: str = \"best_solution_C.pt\""],"metadata":{"id":"NpX0z8LUVfKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    labels=labels)\n","\n","    loss = outputs.loss\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.logits.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","    SCHEDULER.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      labels=labels)\n","\n","    loss = outputs.loss.detach().cpu().numpy()\n","    logits = outputs.logits.detach().cpu().numpy()\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")\n","\n","  #Early stopping\n","  if avg_val_loss < (best_val_loss - min_delta):\n","    best_val_loss = avg_val_loss\n","    current_patience = 0\n","\n","    #Save the best model so far\n","    torch.save(model.state_dict(), os.path.join(models_dir, best_model_filename))\n","    print(f\"Best model recorded at epoch {epoch+1}\")\n","  else:\n","    current_patience += 1\n","    if current_patience >= patience:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break"],"metadata":{"id":"boPFGqRKaL16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Load in the best saved model\n","model.load_state_dict(torch.load(os.path.join(models_dir, best_model_filename))) #Disabled loading in the best model so far. Found that the later model performs better"],"metadata":{"id":"6qfQjsE2lh2z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_logits = []\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    labels=labels)\n","\n","  predicted_logits.extend(outputs.logits.detach().cpu())"],"metadata":{"id":"28szS3zhaNn8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_metrics = evaluate(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))\n","test_metrics.to_csv(os.path.join(results_dir, \"roberta_metrics.csv\"), index=False)\n","test_metrics.head()"],"metadata":{"id":"ykToO7-7pZzj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conf_mat = draw_confusion_matrix(true_labels=np.array(dev_labels), predicted_logits=np.array(predicted_logits))"],"metadata":{"id":"W64aU4t0QjrP"},"execution_count":null,"outputs":[]}]}