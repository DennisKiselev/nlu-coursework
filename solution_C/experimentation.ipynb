{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6Z_nt6CDPmFL","5iRsx3jRavN_","NNhHNF_7QCLR","tmplgEhQQGa9","47YHR_RvQKOH","mqj3-EkCamIR","LdCYjvR8h4z0","IJOW-8bZYZ8w","LjMx8_hlTBFM"],"gpuType":"V100","authorship_tag":"ABX9TyNhv7uX/KdjwHsnDD5SUexq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1712156397940,"user_tz":-60,"elapsed":2130,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"a00209e6-a6dd-4d89-bbd0-87ae6ca583eb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import BertForSequenceClassification, BertForPreTraining, BertTokenizer, BertModel\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, precision_recall_fscore_support\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1712161601731,"user_tz":-60,"elapsed":204,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","from nltk.corpus import stopwords\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string\n","import pandas as pd\n","from dataclasses import dataclass"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1712160814629,"user_tz":-60,"elapsed":228,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\"\n","\n","data_dir = os.path.join(cwk_dir, \"data\")\n","\n","solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1712159177867,"user_tz":-60,"elapsed":340,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["TRAIN_FILEPATH: str = os.path.join(data_dir, \"training_data/training_data/NLI\")\n","TRAIN_DATASET: str = os.path.join(TRAIN_FILEPATH, \"train.csv\")\n","DEV_DATASET: str = os.path.join(TRAIN_FILEPATH, \"dev.csv\")\n","\n","TRIAL_FILEPATH: str = os.path.join(data_dir, \"trial_data/trial_data\")\n","TRIAL_DATASET: str = os.path.join(TRIAL_FILEPATH, \"NLI_trial.csv\")"],"metadata":{"id":"_EfyRZsfQD56","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Label variables"],"metadata":{"id":"_mptN-62SHic"}},{"cell_type":"code","source":["PREMISE_KEY: str = \"premise\"\n","HYPOTHESIS_KEY: str = \"hypothesis\"\n","LABEL_KEY: str = \"label\""],"metadata":{"id":"03yWAIjVSJ8I","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 4\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","BERT_ID: str = 'bert-base-uncased'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def load_data_csv(filepath: str) -> typing.Tuple[typing.List[str], typing.List[str], typing.List[int]]:\n","  \"\"\"\n","  Will load in data from the filepath specified. Expects the string filepath to a csv file. Returns tuple of the premises, hypotheses and labels\n","  \"\"\"\n","  dataset = pd.read_csv(filepath).to_dict()\n","  premises = list(map(str, dataset[PREMISE_KEY].values()))\n","  hypotheses = list(map(str, dataset[HYPOTHESIS_KEY].values()))\n","  labels = list(map(int, dataset[LABEL_KEY].values()))\n","  return (premises, hypotheses,labels)"],"metadata":{"id":"UQUgKlBFQF27","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def tokenize_data(tokenizer: BertTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class MacroMetric:\n","  \"\"\"\n","  Dataclass for metrics that can be turned into macro & weighted macro\n","  \"\"\"\n","  NORMAL_KEY: str\n","  MACRO_KEY: str\n","  WEIGHTED_KEY: str\n","\n","  def __init__(self, key: str):\n","    self.NORMAL_KEY: str = key\n","    self.MACRO_KEY: str = f\"Macro {key}\"\n","    self.WEIGHTED_KEY: str = f\"Weighted Macro {key}\"\n","\n","@dataclass(frozen=True)\n","class MetricKeys:\n","  \"\"\"\n","  Dataclass associated with keys for the evaluation metrics\n","  \"\"\"\n","  ACCURACY_KEY: str = \"Accuracy\"\n","  PRECISION: MacroMetric = MacroMetric(key=\"Precision\")\n","  F1: MacroMetric = MacroMetric(key=\"F1-Score\")\n","  RECALL: MacroMetric = MacroMetric(key=\"Recall\")\n","  MCC_KEY: str = \"MCC\"\n","\n","def get_metrics(true_labels: np.array, predicted_labels: np.array) -> pd.DataFrame:\n","  \"\"\"\n","  Uses the true and predicted labels & sklearn to create extensive evaluation metrics. Formats into a dataframe that it displays & returns\n","  \"\"\"\n","  accuracy = accuracy_score(true_labels, predicted_labels)\n","\n","  precision, recall, f1, support = precision_recall_fscore_support(true_labels, predicted_labels)\n","\n","  weighted_precision = np.average(precision, weights=support)\n","  weighted_recall = np.average(recall, weights=support)\n","  weighted_f1 = np.average(f1, weights=support)\n","\n","  precision = precision_score(true_labels, predicted_labels)\n","  recall = recall_score(true_labels, predicted_labels)\n","  f1 = f1_score(true_labels, predicted_labels)\n","\n","  macro_precision = precision_score(true_labels, predicted_labels, average='macro')\n","  macro_recall = recall_score(true_labels, predicted_labels, average='macro')\n","  macro_f1 = f1_score(true_labels, predicted_labels, average='macro')\n","\n","  mcc = matthews_corrcoef(true_labels, predicted_labels)\n","\n","  #Format into dataframe for easier viewing\n","  df = pd.DataFrame([[accuracy,\n","                      precision, macro_precision, weighted_precision,\n","                      recall, macro_recall, weighted_recall,\n","                      f1, macro_f1, weighted_f1,\n","                      mcc]],\n","                    columns=[MetricKeys.ACCURACY_KEY,\n","                             MetricKeys.PRECISION.NORMAL_KEY, MetricKeys.PRECISION.MACRO_KEY, MetricKeys.PRECISION.WEIGHTED_KEY,\n","                             MetricKeys.RECALL.NORMAL_KEY, MetricKeys.RECALL.MACRO_KEY, MetricKeys.RECALL.WEIGHTED_KEY,\n","                             MetricKeys.F1.NORMAL_KEY, MetricKeys.F1.MACRO_KEY, MetricKeys.F1.WEIGHTED_KEY,\n","                             MetricKeys.MCC_KEY])\n","  return df"],"metadata":{"id":"D_2C7Oain8Gv","executionInfo":{"status":"ok","timestamp":1712161915708,"user_tz":-60,"elapsed":207,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["train_premises, train_hypotheses, train_labels = load_data_csv(filepath=TRAIN_DATASET)\n","dev_premises, dev_hypotheses, dev_labels = load_data_csv(filepath=DEV_DATASET)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1712156420027,"user_tz":-60,"elapsed":795,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor(train_labels)\n","dev_labels = torch.tensor(dev_labels)"],"metadata":{"id":"mCMCOuTGYOTA","executionInfo":{"status":"ok","timestamp":1712156420027,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1712156421556,"user_tz":-60,"elapsed":1534,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"4e97b10f-a045-4f94-cbca-f4a2ae650f70"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1712156477504,"user_tz":-60,"elapsed":55951,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Example of a sentence:"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHvMInfZduYR","executionInfo":{"status":"ok","timestamp":1712156477505,"user_tz":-60,"elapsed":35,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"64f9d69d-2d5e-41dc-f829-5cbf8983b8f1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['[CLS]', 'however', ',', 'fort', 'charles', 'was', 'rebuilt', 'as', 'a', 'military', 'and', 'naval', 'garrison', ',', 'and', 'it', 'protected', 'jamaica', 'and', 'much', 'of', 'the', 'english', 'caribbean', 'for', '250', 'years', 'until', 'the', 'advent', 'of', 'steamship', '##s', 'and', 'yet', 'another', 'earthquake', 'in', '1907', 'saw', 'its', 'decline', '.', '[SEP]', 'fort', 'charles', 'was', 'rebuilt', 'as', 'an', 'amusement', 'park', 'for', 'the', 'locals', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","Tokens: tensor([[  101,  2174,  1010,  ...,     0,     0,     0],\n","        [  101, 14349,  1005,  ...,     0,     0,     0],\n","        [  101,  1999,  2344,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2058,  1996,  ...,     0,     0,     0],\n","        [  101,  9444,  2034,  ...,     0,     0,     0],\n","        [  101,  2021,  1045,  ...,     0,     0,     0]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cuinRLeI-H","executionInfo":{"status":"ok","timestamp":1712156477506,"user_tz":-60,"elapsed":25,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"cad018ca-ad3a-4157-b199-69fe54befe01"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 30522\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_data[TOKEN_TYPE_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_data[TOKEN_TYPE_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1712156477506,"user_tz":-60,"elapsed":24,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":22,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":22,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLSa4oiWqbny","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":21,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"e788d9f5-1c3d-4098-9283-ef34815e67fb"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["class BERT_NLI(torch.nn.Module):\n","  \"\"\"\n","  Class for extended BERT models\n","  \"\"\"\n","  def __init__(self, bert_model: BertForSequenceClassification, output_dim: int, hidden_dim: int = 100):\n","    super().__init__()\n","    self.bert = bert_model\n","    embedding_dim = bert_model.config.to_dict()['hidden_size']\n","\n","    self.hidden_linear = Linear(embedding_dim, hidden_dim)\n","    self.out = Linear(hidden_dim, output_dim)\n","\n","  def forward(self, input_ids, attention_mask, token_type_ids):\n","    #Embed with BERT\n","    embedded = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[1]\n","\n","    #Pass on to further layers\n","    x = self.hidden_linear(embedded)\n","    output = self.out(x)\n","    return output"],"metadata":{"id":"Q8cjfXusPwLC","executionInfo":{"status":"ok","timestamp":1712156477508,"user_tz":-60,"elapsed":19,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["bert_model = BertModel.from_pretrained(BERT_ID)\n","model = BERT_NLI(bert_model=bert_model, output_dim=NUM_LABELS)\n","model = model.to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeDsauNmP92-","executionInfo":{"status":"ok","timestamp":1712156478228,"user_tz":-60,"elapsed":738,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"d45cb6c8-ccf8-4c04-8f10-f421d6f780c9"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERT_NLI(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (hidden_linear): Linear(in_features=768, out_features=100, bias=True)\n","  (out): Linear(in_features=100, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)"],"metadata":{"id":"FWZ8X9VITCdA","executionInfo":{"status":"ok","timestamp":1712156479019,"user_tz":-60,"elapsed":795,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ","executionInfo":{"status":"ok","timestamp":1712156479020,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    token_type_ids=token_type_ids)\n","\n","    loss = loss_function(outputs, labels.squeeze())\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  best_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      token_type_ids=token_type_ids)\n","\n","    loss = loss_function(outputs, labels.squeeze())\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(outputs.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"05603ecb-6823-4c6f-c255-5531ce5e84c7","executionInfo":{"status":"ok","timestamp":1712159158114,"user_tz":-60,"elapsed":352327,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.7535701038575667, Training Average Loss: 0.4871030089940091\n","Epoch 1, Validation Average Accuracy: 0.8286350148367952, Validation Average Loss: 0.3840154116249226\n","Epoch 2, Train Average Accuracy: 0.8952151335311572, Training Average Loss: 0.26323975030697594\n","Epoch 2, Validation Average Accuracy: 0.8379080118694362, Validation Average Loss: 0.39922536002024345\n","Epoch 3, Train Average Accuracy: 0.9610070474777448, Training Average Loss: 0.11089881508385221\n","Epoch 3, Validation Average Accuracy: 0.8403808110781404, Validation Average Loss: 0.4901121566417552\n","Epoch 4, Train Average Accuracy: 0.9796921364985163, Training Average Loss: 0.05999692285494555\n","Epoch 4, Validation Average Accuracy: 0.8350642927794264, Validation Average Loss: 0.6275315359773705\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1712159197677,"user_tz":-60,"elapsed":10154,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_labels = []\n","total_test_loss = 0\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    token_type_ids=token_type_ids)\n","\n","  loss = loss_function(outputs, labels)\n","  total_test_loss  += loss.item()\n","\n","  predicted_labels.extend(torch.argmax(outputs.detach().cpu(), dim=1).numpy())"],"metadata":{"id":"28szS3zhaNn8","executionInfo":{"status":"ok","timestamp":1712159767744,"user_tz":-60,"elapsed":64175,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["#Loss\n","avg_test_loss = total_val_loss / len(test_dataloader)\n","print(f\"Average Test loss: {avg_test_loss}\")\n","\n","#Other metrics\n","test_metrics = get_metrics(true_labels=np.array(dev_labels), predicted_labels=np.array(predicted_labels))\n","test_metrics.head()\n","test_metrics.to_csv(os.path.join(results_dir, \"metrics.csv\"), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"ykToO7-7pZzj","executionInfo":{"status":"error","timestamp":1712162096464,"user_tz":-60,"elapsed":205,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"3b047981-d079-4951-8a90-cce25965b06b"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Test loss: 0.5011330038492272\n"]},{"output_type":"error","ename":"OSError","evalue":"Cannot save file into a non-existent directory: 'drive/MyDrive/NLU Coursework/solution_C/results'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-87-059515998256>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"metrics.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3718\u001b[0m         )\n\u001b[1;32m   3719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3720\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3721\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3722\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         )\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'drive/MyDrive/NLU Coursework/solution_C/results'"]}]}]}