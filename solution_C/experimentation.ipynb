{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["mqj3-EkCamIR","LdCYjvR8h4z0","IJOW-8bZYZ8w","LjMx8_hlTBFM"],"gpuType":"V100","authorship_tag":"ABX9TyMbkSC0b44FXqJMUjXOeErx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","import sys\n","\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1712162876550,"user_tz":-60,"elapsed":2678,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"2177dc56-2d0f-4ca3-c5a0-8c09df3f6988"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\""],"metadata":{"id":"-rSAojhC3LDJ","executionInfo":{"status":"ok","timestamp":1712162913825,"user_tz":-60,"elapsed":286,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["sys.path.append(cwk_dir)\n","from classes.evaluation import evaluate\n","from classes.preprocessing import load_data_csv"],"metadata":{"id":"b7x9JKYX2ehs","executionInfo":{"status":"ok","timestamp":1712163181391,"user_tz":-60,"elapsed":795,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","from transformers import BertForSequenceClassification, BertForPreTraining, BertTokenizer, BertModel\n","from torch.nn import Linear, AvgPool2d, CrossEntropyLoss\n","\n","import torch"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1712161601731,"user_tz":-60,"elapsed":204,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","from nltk.corpus import stopwords\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1712160814629,"user_tz":-60,"elapsed":228,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["data_dir = os.path.join(cwk_dir, \"data\")\n","\n","solution_dir = os.path.join(cwk_dir, \"solution_C\")\n","models_dir = os.path.join(solution_dir, \"models\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1712159177867,"user_tz":-60,"elapsed":340,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["TRAIN_FILEPATH: str = os.path.join(data_dir, \"training_data/training_data/NLI\")\n","TRAIN_DATASET: str = os.path.join(TRAIN_FILEPATH, \"train.csv\")\n","DEV_DATASET: str = os.path.join(TRAIN_FILEPATH, \"dev.csv\")\n","\n","TRIAL_FILEPATH: str = os.path.join(data_dir, \"trial_data/trial_data\")\n","TRIAL_DATASET: str = os.path.join(TRIAL_FILEPATH, \"NLI_trial.csv\")"],"metadata":{"id":"_EfyRZsfQD56","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":8,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 2e-5\n","EPOCHS: int = 4\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","BERT_ID: str = 'bert-base-uncased'\n","NUM_LABELS: int = 2"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["BERT Keys"],"metadata":{"id":"qsTe_2K1OkNu"}},{"cell_type":"code","source":["INPUTS_IDS_KEY: str = \"input_ids\"\n","ATTENTION_MASK_KEY: str = \"attention_mask\"\n","TOKEN_TYPE_KEY: str = \"token_type_ids\""],"metadata":{"id":"heN1O-nCOlyj","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def tokenize_data(tokenizer: BertTokenizer, premises: typing.List[str], hypotheses: typing.List[str], maxlen: int) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=maxlen, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1712156419238,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"7SnGYqV91Zct"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["train_premises, train_hypotheses, train_labels = load_data_csv(filepath=TRAIN_DATASET)\n","dev_premises, dev_hypotheses, dev_labels = load_data_csv(filepath=DEV_DATASET)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1712163189928,"user_tz":-60,"elapsed":511,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.tensor(train_labels)\n","dev_labels = torch.tensor(dev_labels)"],"metadata":{"id":"mCMCOuTGYOTA","executionInfo":{"status":"ok","timestamp":1712156420027,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(BERT_ID, do_lower_case=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1712156421556,"user_tz":-60,"elapsed":1534,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"4e97b10f-a045-4f94-cbca-f4a2ae650f70"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses), maxlen=MAX_SEQ_LENGTH)\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses), maxlen=MAX_SEQ_LENGTH) #Dev is used for evaluation"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1712156477504,"user_tz":-60,"elapsed":55951,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Example of a sentence:"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data[INPUTS_IDS_KEY][0])}\")\n","print(f\"Tokens: {train_data[INPUTS_IDS_KEY]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHvMInfZduYR","executionInfo":{"status":"ok","timestamp":1712156477505,"user_tz":-60,"elapsed":35,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"64f9d69d-2d5e-41dc-f829-5cbf8983b8f1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['[CLS]', 'however', ',', 'fort', 'charles', 'was', 'rebuilt', 'as', 'a', 'military', 'and', 'naval', 'garrison', ',', 'and', 'it', 'protected', 'jamaica', 'and', 'much', 'of', 'the', 'english', 'caribbean', 'for', '250', 'years', 'until', 'the', 'advent', 'of', 'steamship', '##s', 'and', 'yet', 'another', 'earthquake', 'in', '1907', 'saw', 'its', 'decline', '.', '[SEP]', 'fort', 'charles', 'was', 'rebuilt', 'as', 'an', 'amusement', 'park', 'for', 'the', 'locals', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","Tokens: tensor([[  101,  2174,  1010,  ...,     0,     0,     0],\n","        [  101, 14349,  1005,  ...,     0,     0,     0],\n","        [  101,  1999,  2344,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2058,  1996,  ...,     0,     0,     0],\n","        [  101,  9444,  2034,  ...,     0,     0,     0],\n","        [  101,  2021,  1045,  ...,     0,     0,     0]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cuinRLeI-H","executionInfo":{"status":"ok","timestamp":1712156477506,"user_tz":-60,"elapsed":25,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"cad018ca-ad3a-4157-b199-69fe54befe01"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 30522\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Dataloader"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[INPUTS_IDS_KEY], train_data[ATTENTION_MASK_KEY], train_data[TOKEN_TYPE_KEY], train_labels)\n","test_dataset = TensorDataset(dev_data[INPUTS_IDS_KEY], dev_data[ATTENTION_MASK_KEY], dev_data[TOKEN_TYPE_KEY], dev_labels) #note here that the dev dataset is used for testing (evaluation) later"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1712156477506,"user_tz":-60,"elapsed":24,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":22,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":22,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"markdown","source":["## Model Architecture"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLSa4oiWqbny","executionInfo":{"status":"ok","timestamp":1712156477507,"user_tz":-60,"elapsed":21,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"e788d9f5-1c3d-4098-9283-ef34815e67fb"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["class BERT_NLI(torch.nn.Module):\n","  \"\"\"\n","  Class for extended BERT models\n","  \"\"\"\n","  def __init__(self, bert_model: BertForSequenceClassification, output_dim: int, hidden_dim: int = 100):\n","    super().__init__()\n","    self.bert = bert_model\n","    embedding_dim = bert_model.config.to_dict()['hidden_size']\n","\n","    self.hidden_linear = Linear(embedding_dim, hidden_dim)\n","    self.out = Linear(hidden_dim, output_dim)\n","\n","  def forward(self, input_ids, attention_mask, token_type_ids):\n","    #Embed with BERT\n","    embedded = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)[1]\n","\n","    #Pass on to further layers\n","    x = self.hidden_linear(embedded)\n","    output = self.out(x)\n","    return output"],"metadata":{"id":"Q8cjfXusPwLC","executionInfo":{"status":"ok","timestamp":1712156477508,"user_tz":-60,"elapsed":19,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["bert_model = BertModel.from_pretrained(BERT_ID)\n","model = BERT_NLI(bert_model=bert_model, output_dim=NUM_LABELS)\n","model = model.to(device)\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XeDsauNmP92-","executionInfo":{"status":"ok","timestamp":1712156478228,"user_tz":-60,"elapsed":738,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"d45cb6c8-ccf8-4c04-8f10-f421d6f780c9"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BERT_NLI(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (hidden_linear): Linear(in_features=768, out_features=100, bias=True)\n","  (out): Linear(in_features=100, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"LjMx8_hlTBFM"}},{"cell_type":"code","source":["OPTIM = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)"],"metadata":{"id":"FWZ8X9VITCdA","executionInfo":{"status":"ok","timestamp":1712156479019,"user_tz":-60,"elapsed":795,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["#Loss metric\n","loss_function = CrossEntropyLoss().to(device)"],"metadata":{"id":"4Hxa9FaMTPSQ","executionInfo":{"status":"ok","timestamp":1712156479020,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","    OPTIM.zero_grad()\n","\n","    input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","    outputs = model(input_ids=input_ids,\n","                    attention_mask=attention_mask,\n","                    token_type_ids=token_type_ids)\n","\n","    loss = loss_function(outputs, labels.squeeze())\n","    total_loss += loss.item()\n","    loss.backward()\n","\n","    total_accuracy += get_accuracy(outputs.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","    OPTIM.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  best_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","    with torch.no_grad():\n","      outputs = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      token_type_ids=token_type_ids)\n","\n","    loss = loss_function(outputs, labels.squeeze())\n","    total_val_loss  += loss.item()\n","\n","    total_val_accuracy += get_accuracy(outputs.detach().cpu().numpy(), labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"05603ecb-6823-4c6f-c255-5531ce5e84c7","executionInfo":{"status":"ok","timestamp":1712159158114,"user_tz":-60,"elapsed":352327,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.7535701038575667, Training Average Loss: 0.4871030089940091\n","Epoch 1, Validation Average Accuracy: 0.8286350148367952, Validation Average Loss: 0.3840154116249226\n","Epoch 2, Train Average Accuracy: 0.8952151335311572, Training Average Loss: 0.26323975030697594\n","Epoch 2, Validation Average Accuracy: 0.8379080118694362, Validation Average Loss: 0.39922536002024345\n","Epoch 3, Train Average Accuracy: 0.9610070474777448, Training Average Loss: 0.11089881508385221\n","Epoch 3, Validation Average Accuracy: 0.8403808110781404, Validation Average Loss: 0.4901121566417552\n","Epoch 4, Train Average Accuracy: 0.9796921364985163, Training Average Loss: 0.05999692285494555\n","Epoch 4, Validation Average Accuracy: 0.8350642927794264, Validation Average Loss: 0.6275315359773705\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1712159197677,"user_tz":-60,"elapsed":10154,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation\n","Here we have balanced data & both classes are equally important. Therefore it is best to look at the macro-averaged performance metrics. Below details the metrics of:\n","- Accuracy\n","- Loss\n","- Precision\n","  - Macro\n","  - Weighted Macro\n","- Recall\n","  - Macro\n","  - Weighted Macro\n","- F-Score\n","  - Macro\n","  - Weighted Macro\n","- MCC\n"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["#Get the predictions for all of the test cases\n","predicted_labels = []\n","total_test_loss = 0\n","\n","for batch in test_dataloader:\n","  input_ids, attention_mask, token_type_ids, labels = [part.to(device) for part in batch]\n","\n","  with torch.no_grad():\n","    outputs = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    token_type_ids=token_type_ids)\n","\n","  loss = loss_function(outputs, labels)\n","  total_test_loss  += loss.item()\n","\n","  predicted_labels.extend(torch.argmax(outputs.detach().cpu(), dim=1).numpy())"],"metadata":{"id":"28szS3zhaNn8","executionInfo":{"status":"ok","timestamp":1712159767744,"user_tz":-60,"elapsed":64175,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["#Loss\n","avg_test_loss = total_val_loss / len(test_dataloader)\n","print(f\"Average Test loss: {avg_test_loss}\")\n","\n","#Other metrics\n","test_metrics = evaluate(true_labels=np.array(dev_labels), predicted_labels=np.array(predicted_labels))\n","test_metrics.head()\n","test_metrics.to_csv(os.path.join(results_dir, \"metrics.csv\"), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykToO7-7pZzj","executionInfo":{"status":"ok","timestamp":1712162923343,"user_tz":-60,"elapsed":307,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"09798552-d799-4f51-e830-89dffe2805c3"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Test loss: 0.5011330038492272\n"]}]}]}