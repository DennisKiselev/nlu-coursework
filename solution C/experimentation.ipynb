{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Ar8n9iYLRqJ-","7PIjaoLxQETl","tmplgEhQQGa9","XL5qpjqCkoq8","IJOW-8bZYZ8w","nZX8TUrrnDJK"],"gpuType":"A100","authorship_tag":"ABX9TyPOFshhtVqBYOug5fFUdp4n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,garbage_collection_threshold:0.8"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywDNUgiOsypn","executionInfo":{"status":"ok","timestamp":1711561251213,"user_tz":0,"elapsed":321,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"e671f59e-b0fd-488b-8e60-c1c3432e820e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,garbage_collection_threshold:0.8\n"]}]},{"cell_type":"code","source":["%env PYTORCH_CUDA_ALLOC_CONF"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"-gj0ch4DyetI","executionInfo":{"status":"ok","timestamp":1711561251544,"user_tz":0,"elapsed":18,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"bd2d459a-a22b-47d6-9f35-38a73621c7c6"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'expandable_segments:True,garbage_collection_threshold:0.8'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"6Z_nt6CDPmFL"}},{"cell_type":"markdown","source":["## Connect Google Drive Folder"],"metadata":{"id":"5iRsx3jRavN_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueUCEpZiaxb6","executionInfo":{"status":"ok","timestamp":1711561253075,"user_tz":0,"elapsed":1546,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"0a11a296-44a1-4998-890a-99b9702e09f0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"Ar8n9iYLRqJ-"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"Xu6_MOGrOgk7","executionInfo":{"status":"ok","timestamp":1711561258279,"user_tz":0,"elapsed":5207,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"outputs":[],"source":["from tensorflow.keras import utils\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Add, Layer, LSTM, Bidirectional, Embedding, concatenate, BatchNormalization, SimpleRNN, Attention, GlobalMaxPooling1D, GlobalAveragePooling1D, Conv1D, MaxPooling1D, TimeDistributed\n","from tensorflow.keras.optimizers.legacy import SGD, Adam, RMSprop\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.callbacks import Callback\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.keras.metrics import SparseCategoricalAccuracy as Acc\n","from tensorflow.keras.metrics import SparseTopKCategoricalAccuracy as KAcc\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.regularizers import l2\n","\n","import keras"]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, SequentialSampler,random_split\n","import torch\n","from transformers import BertForSequenceClassification"],"metadata":{"id":"RngEqRiIh1Wl","executionInfo":{"status":"ok","timestamp":1711561264374,"user_tz":0,"elapsed":6109,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import typing\n","from PIL import Image\n","import json\n","from nltk.corpus import stopwords\n","import gensim.downloader as api\n","from gensim.models import Word2Vec\n","import nltk\n","from nltk.tokenize import word_tokenize\n","import string"],"metadata":{"id":"9stsorj3fgDx","executionInfo":{"status":"ok","timestamp":1711561265553,"user_tz":0,"elapsed":1190,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel"],"metadata":{"id":"a_HjaQUzRIBR","executionInfo":{"status":"ok","timestamp":1711561265553,"user_tz":0,"elapsed":7,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Primary Variables"],"metadata":{"id":"NNhHNF_7QCLR"}},{"cell_type":"markdown","source":["Filepath variables"],"metadata":{"id":"2QuJjCaZSGKQ"}},{"cell_type":"code","source":["cwk_dir =\"drive/MyDrive/NLU Coursework/\"\n","\n","data_dir = os.path.join(cwk_dir, \"data\")\n","\n","solution_dir = os.path.join(cwk_dir, \"solution C\")\n","models_dir = os.path.join(solution_dir, \"models\")\n","results_dir = os.path.join(solution_dir, \"results\")"],"metadata":{"id":"Ca4vAm0rshSC","executionInfo":{"status":"ok","timestamp":1711561265554,"user_tz":0,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["TRAIN_FILEPATH: str = os.path.join(data_dir, \"training_data/training_data/NLI\")\n","TRAIN_DATASET: str = os.path.join(TRAIN_FILEPATH, \"train.csv\")\n","DEV_DATASET: str = os.path.join(TRAIN_FILEPATH, \"dev.csv\")\n","\n","TRIAL_FILEPATH: str = os.path.join(data_dir, \"trial_data/trial_data\")\n","TRIAL_DATASET: str = os.path.join(TRIAL_FILEPATH, \"NLI_trial.csv\")"],"metadata":{"id":"_EfyRZsfQD56","executionInfo":{"status":"ok","timestamp":1711561265554,"user_tz":0,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Label variables"],"metadata":{"id":"_mptN-62SHic"}},{"cell_type":"code","source":["PREMISE_KEY: str = \"premise\"\n","HYPOTHESIS_KEY: str = \"hypothesis\"\n","LABEL_KEY: str = \"label\""],"metadata":{"id":"03yWAIjVSJ8I","executionInfo":{"status":"ok","timestamp":1711561265554,"user_tz":0,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Preprocessing variables"],"metadata":{"id":"V9ZpgIEce2m_"}},{"cell_type":"code","source":["LOWER: bool = True\n","PADDING: str = \"post\"\n","\n","nltk.download('stopwords')\n","STOP_WORDS = set(stopwords.words('english'))"],"metadata":{"id":"wD-vIHW0e4JC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711561265554,"user_tz":0,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"82c4b083-245f-4982-8083-a7c88fe96842"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["Training variables"],"metadata":{"id":"MCtnUhDpVdGS"}},{"cell_type":"code","source":["INITIAL_LR: float = 0.0001\n","EPOCHS: int = 4\n","VALIDATION_SPLIT: float = 0.2\n","BATCH_SIZE: int = 16\n","\n","DROPOUT: float = 0.25\n","\n","# OPTIMIZER = RMSprop(INITIAL_LR)\n","OPTIMIZER = \"adam\"\n","\n","BERT_ID = 'bert-base-uncased'"],"metadata":{"id":"reO2X7MfVer7","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":330,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["Other"],"metadata":{"id":"Ae8SvQ7sVsZL"}},{"cell_type":"code","source":["MAX_SEQ_LENGTH: int = 512 #None is the value to denote that there is no max length. Max length is recommended\n","VOCAB_SIZE: int = None #None is the value to denote that there is no vocab size yet. This is set later, once we have the training data\n","EMBEDDING_SIZE: int = None"],"metadata":{"id":"o3eLxvA4VtPT","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":5,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Functions"],"metadata":{"id":"7PIjaoLxQETl"}},{"cell_type":"code","source":["def load_data_csv(filepath: str) -> typing.Tuple[typing.List[str], typing.List[str], typing.List[int]]:\n","  \"\"\"\n","  Will load in data from the filepath specified. Expects the string filepath to a csv file. Returns tuple of the premises, hypotheses and labels\n","  \"\"\"\n","  dataset = pd.read_csv(filepath).to_dict()\n","  premises = list(map(str, dataset[PREMISE_KEY].values()))\n","  hypotheses = list(map(str, dataset[HYPOTHESIS_KEY].values()))\n","  labels = list(map(int, dataset[LABEL_KEY].values()))\n","  return (premises, hypotheses,labels)"],"metadata":{"id":"UQUgKlBFQF27","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def show_model_architecture(model: Model, filename: str) -> None:\n","  \"\"\"\n","  Takes a model architecture and will a diagram of the architecture. Saves this diagram also, to the filename specified\n","  \"\"\"\n","  model.summary()\n","  filename = os.path.join(results_dir, filename)\n","  plot_model(model, to_file=filename)\n","  img = Image.open(filename)\n","  fig, ax = plt.subplots(figsize=(15, 15))\n","  plt.imshow(img, aspect='equal')"],"metadata":{"id":"lFtwPpokZA-M","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def tokenize_data(tokenizer: BertTokenizer, premises: typing.List[str], hypotheses: typing.List[str]) ->typing.Tuple[np.array, np.array]:\n","  \"\"\"\n","  Uses the input tokenizer to tokenizer the premises & hypotheses together. Will padd/truncate the sequences of tokens correctly. Formats the sequences together of the format below\n","\n","      sample = [CLS] Premise [SEP] Hypothesis [SEP]\n","  \"\"\"\n","  return tokenizer(premises, hypotheses, max_length=MAX_SEQ_LENGTH, padding=\"max_length\", truncation=True, return_tensors=\"pt\", add_special_tokens=True)"],"metadata":{"id":"AXdTexuHfnr-","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def clean_sentences(sentences: typing.List[str]) -> typing.List[str]:\n","  \"\"\"\n","  Takes a list of sentences & cleans them. Remove stopwords, reduces to lower case, removes punctuation\n","  \"\"\"\n","  sentences = [[word.lower().translate(str.maketrans(\"\",\"\",string.punctuation)) for word in sentence.split(\" \") if word not in STOP_WORDS] for sentence in sentences]\n","  sentences = np.array([\" \".join(sentence) for sentence in sentences])\n","  return sentences\n"],"metadata":{"id":"3PyD8IgR8qfX","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def plot_history(history, export_path, legend: typing.List[str] = ['train', 'test']):\n","  \"\"\"\n","  Will plot the history of a model, labelling it appropriately\n","  \"\"\"\n","  plt.figure(figsize=(20, 10))\n","  plt.subplot(1, 2, 1)\n","\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('model accuracy')\n","  plt.ylabel('accuracy')\n","  plt.xlabel('epoch')\n","  plt.legend(legend, loc='upper left')\n","\n","  plt.subplot(1, 2, 2)\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('model loss')\n","  plt.ylabel('loss')\n","  plt.xlabel('epoch')\n","  plt.legend(legend, loc='upper left')\n","\n","  plt.savefig(os.path.join(results_dir, export_path))\n","\n","  plt.show()\n"],"metadata":{"id":"t-ctea8YAD3d","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(preds, labels) -> float:\n","  \"\"\"\n","  Gets the accuracy between the predictions and labels. Returns this float\n","  \"\"\"\n","  pred_flat = np.argmax(preds, axis=1).flatten()\n","  labels_flat = labels.flatten()\n","  return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"metadata":{"id":"D_2C7Oain8Gv","executionInfo":{"status":"ok","timestamp":1711561265880,"user_tz":0,"elapsed":3,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"tmplgEhQQGa9"}},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"47YHR_RvQKOH"}},{"cell_type":"code","source":["train_premises, train_hypotheses, train_labels = load_data_csv(filepath=TRAIN_DATASET)\n","dev_premises, dev_hypotheses, dev_labels = load_data_csv(filepath=DEV_DATASET)"],"metadata":{"id":"lQwHWpA_QLJ8","executionInfo":{"status":"ok","timestamp":1711561266738,"user_tz":0,"elapsed":861,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train_labels = torch.reshape(torch.tensor(train_labels), (len(train_labels),1))\n","dev_labels = torch.reshape(torch.tensor(dev_labels), (len(dev_labels),1))"],"metadata":{"id":"mCMCOuTGYOTA","executionInfo":{"status":"ok","timestamp":1711561266738,"user_tz":0,"elapsed":4,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#Removes stop words, reduces to lower case and will shorten to the max length\n","train_premises = clean_sentences(sentences=train_premises)\n","train_hypotheses = clean_sentences(sentences=train_hypotheses)\n","\n","dev_premises = clean_sentences(sentences=dev_premises)\n","dev_hypotheses = clean_sentences(sentences=dev_hypotheses)"],"metadata":{"id":"W6-dSfMA8nwP","executionInfo":{"status":"ok","timestamp":1711561272307,"user_tz":0,"elapsed":5572,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize Data"],"metadata":{"id":"mqj3-EkCamIR"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(BERT_ID, do_lower_case=True)\n","bert_model = BertModel.from_pretrained(BERT_ID)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mHVdTUoRcY0","executionInfo":{"status":"ok","timestamp":1711561275794,"user_tz":0,"elapsed":3499,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"b0e4d41f-cc3b-484e-8fce-963d07addc6c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["train_data = tokenize_data(tokenizer=tokenizer, premises=list(train_premises), hypotheses=list(train_hypotheses))\n","dev_data = tokenize_data(tokenizer=tokenizer, premises=list(dev_premises), hypotheses=list(dev_hypotheses))"],"metadata":{"id":"em9n7xwPbuuI","executionInfo":{"status":"ok","timestamp":1711561312616,"user_tz":0,"elapsed":36826,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Example of a sentence:"],"metadata":{"id":"MuO-c_ej_Pp7"}},{"cell_type":"code","source":["print(f\"Sentence: {tokenizer.convert_ids_to_tokens(train_data['input_ids'][0])}\")\n","print(f\"Tokens: {train_data['input_ids']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gHvMInfZduYR","executionInfo":{"status":"ok","timestamp":1711561312618,"user_tz":0,"elapsed":41,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"181ca4e3-0271-46cf-c3d4-a64c00b2f0f9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: ['[CLS]', 'however', 'fort', 'charles', 'rebuilt', 'military', 'naval', 'garrison', 'protected', 'jamaica', 'much', 'english', 'caribbean', '250', 'years', 'advent', 'steamship', '##s', 'yet', 'another', 'earthquake', '1907', 'saw', 'decline', '[SEP]', 'fort', 'charles', 'rebuilt', 'amusement', 'park', 'locals', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","Tokens: tensor([[  101,  2174,  3481,  ...,     0,     0,     0],\n","        [  101, 14349,  2015,  ...,     0,     0,     0],\n","        [  101,  1999,  2344,  ...,     0,     0,     0],\n","        ...,\n","        [  101,  2058,  2627,  ...,     0,     0,     0],\n","        [  101,  9444,  2034,  ...,     0,     0,     0],\n","        [  101,  2021,  1045,  ...,     0,     0,     0]])\n"]}]},{"cell_type":"code","source":["VOCAB_SIZE = tokenizer.vocab_size\n","print(f\"Vocabulary size: {VOCAB_SIZE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cuinRLeI-H","executionInfo":{"status":"ok","timestamp":1711561312618,"user_tz":0,"elapsed":28,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"065865dd-3600-42da-9efd-8c5d9ba92d5c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 30522\n"]}]},{"cell_type":"markdown","source":["## Format Dataset & Data Split"],"metadata":{"id":"LdCYjvR8h4z0"}},{"cell_type":"code","source":["dataset = TensorDataset(train_data[\"input_ids\"], train_data[\"attention_mask\"], train_labels)\n","test_dataset = TensorDataset(dev_data[\"input_ids\"], dev_data[\"attention_mask\"], dev_labels)"],"metadata":{"id":"IRcaWI0ph8g4","executionInfo":{"status":"ok","timestamp":1711561312619,"user_tz":0,"elapsed":27,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["train_dataset, val_dataset = random_split(dataset, [(1 - VALIDATION_SPLIT), VALIDATION_SPLIT])"],"metadata":{"id":"3Eb5kBXCkKOa","executionInfo":{"status":"ok","timestamp":1711561312619,"user_tz":0,"elapsed":27,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"T5P9yW21YYd3"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLSa4oiWqbny","executionInfo":{"status":"ok","timestamp":1711561312620,"user_tz":0,"elapsed":27,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"f5d47861-7ff4-4d06-f295-1ede1e770738"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["## Dataloader"],"metadata":{"id":"XL5qpjqCkoq8"}},{"cell_type":"code","source":["train_dataloader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size = BATCH_SIZE)"],"metadata":{"id":"bpfnrM8hkqEr","executionInfo":{"status":"ok","timestamp":1711561312620,"user_tz":0,"elapsed":25,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["## Model Architecture"],"metadata":{"id":"IJOW-8bZYZ8w"}},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(BERT_ID, num_labels = 1, output_attentions = False, output_hidden_states = False)\n","model = model.to(device)"],"metadata":{"id":"psFDCOffYbiE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711561313372,"user_tz":0,"elapsed":777,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"a8f15cb1-9917-45f0-cf2e-679b19807fec"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"markdown","source":["## Learning Rate"],"metadata":{"id":"nZX8TUrrnDJK"}},{"cell_type":"code","source":["optimizer = torch.optim.AdamW(model.parameters(), lr=INITIAL_LR)"],"metadata":{"id":"UpVzUYI3nEbc","executionInfo":{"status":"ok","timestamp":1711561314104,"user_tz":0,"elapsed":734,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["criterion = torch.nn.BCEWithLogitsLoss()"],"metadata":{"id":"ccvnOKcf0wiv","executionInfo":{"status":"ok","timestamp":1711561314105,"user_tz":0,"elapsed":6,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["## Model Training"],"metadata":{"id":"W4JqJVPEaJ-F"}},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  ## Training\n","  model.train()\n","  total_loss = 0\n","  total_accuracy = 0\n","  for batch in train_dataloader:\n","      optimizer.zero_grad()\n","\n","      input_ids = batch[0].to(device)\n","      attention_mask = batch[1].to(device)\n","      labels = batch[2].to(device)\n","\n","      outputs = model(input_ids=input_ids,\n","                      attention_mask=attention_mask,\n","                      labels=labels,\n","                      token_type_ids=None)\n","\n","      loss = criterion(outputs.logits.float(), labels.float())\n","      total_loss += loss.item()\n","      loss.backward()\n","\n","      logits = outputs.logits.detach().cpu().numpy()\n","      total_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","      optimizer.step()\n","\n","  avg_train_loss = total_loss / len(train_dataloader)\n","  avg_train_accuracy = total_accuracy / len(train_dataloader)\n","  print(f\"Epoch {epoch+1}, Train Average Accuracy: {avg_train_accuracy}, Training Average Loss: {avg_train_loss}\")\n","\n","  ##Validation\n","  model.eval()\n","  total_val_accuracy = 0\n","  best_val_accuracy = 0\n","  total_val_loss = 0\n","\n","  for batch in val_dataloader:\n","    input_ids = batch[0].to(device)\n","    attention_mask = batch[1].to(device)\n","    labels = batch[2].to(device)\n","\n","    with torch.no_grad():\n","      output = model(input_ids = input_ids,\n","                      attention_mask = attention_mask,\n","                      labels = labels,\n","                      token_type_ids=None)\n","\n","    loss = criterion(output.logits.float(), labels.float())\n","    total_val_loss  += loss.item()\n","\n","    logits = output.logits.detach().cpu().numpy()\n","    total_val_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","  avg_val_accuracy = total_val_accuracy / len(val_dataloader)\n","  avg_val_loss = total_val_loss / len(val_dataloader)\n","  print(f\"Epoch {epoch+1}, Validation Average Accuracy: {avg_val_accuracy}, Validation Average Loss: {avg_val_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boPFGqRKaL16","outputId":"a76f31c8-452b-4f6c-a793-f73275c66b70","executionInfo":{"status":"ok","timestamp":1711563901532,"user_tz":0,"elapsed":2587433,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Average Accuracy: 0.4834477002967359, Training Average Loss: 0.6979149871834661\n","Epoch 1, Validation Average Accuracy: 0.48306132542037583, Validation Average Loss: 0.6950328875366234\n","Epoch 2, Train Average Accuracy: 0.4833086053412463, Training Average Loss: 0.6978169106588166\n","Epoch 2, Validation Average Accuracy: 0.4831231454005935, Validation Average Loss: 0.6928625957548441\n","Epoch 3, Train Average Accuracy: 0.4833086053412463, Training Average Loss: 0.6973593668343405\n","Epoch 3, Validation Average Accuracy: 0.48324678536102866, Validation Average Loss: 0.6972849913803689\n","Epoch 4, Train Average Accuracy: 0.4834477002967359, Training Average Loss: 0.6988499735866173\n","Epoch 4, Validation Average Accuracy: 0.4831231454005935, Validation Average Loss: 0.6927782500533038\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), os.path.join(models_dir, \"solution_C.pt\"))"],"metadata":{"id":"FyJtJdIssmDJ","executionInfo":{"status":"ok","timestamp":1711563907379,"user_tz":0,"elapsed":5982,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{"id":"QaqeotdSaMPX"}},{"cell_type":"code","source":["total_test_accuracy = 0\n","total_test_loss = 0\n","best_test_accuracy = 0\n","\n","for batch in test_dataloader:\n","  input_ids = batch[0].to(device)\n","  attention_mask = batch[1].to(device)\n","  labels = batch[2].to(device)\n","\n","  with torch.no_grad():\n","    output = model(input_ids = input_ids,\n","                    attention_mask = attention_mask,\n","                    labels = labels,\n","                    token_type_ids=None)\n","\n","  loss = criterion(output.logits.float(), labels.float())\n","  total_test_loss  += loss.item()\n","\n","  logits = output.logits.detach().cpu().numpy()\n","  total_test_accuracy += get_accuracy(logits, labels.to('cpu').numpy())\n","\n","avg_test_accuracy = total_test_accuracy / len(test_dataloader)\n","avg_test_loss = total_val_loss / len(test_dataloader)\n","print(f\"Test Average Accuracy: {avg_test_accuracy}\")\n","print(f\"Test Average Loss: {avg_test_loss}\")"],"metadata":{"id":"28szS3zhaNn8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711563968299,"user_tz":0,"elapsed":60947,"user":{"displayName":"Jack Pay","userId":"06088299984570525080"}},"outputId":"4bcbc6cf-64d0-4086-eaf0-3aeaa7cee0e1"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Average Accuracy: 0.4826718009478673\n","Test Average Loss: 0.5532376072700554\n"]}]}]}